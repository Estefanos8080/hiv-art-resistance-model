{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the CNN model\n",
    "def get_model(bp, nunits):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=bp, output_dim=128, input_length=bp))\n",
    "    model.add(Conv1D(filters=32, kernel_size=9, activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Conv1D(filters=32, kernel_size=9, activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=RMSprop(),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and preprocess FASTA file\n",
    "def read_fasta(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    data = []\n",
    "    for i in range(0, len(lines), 2):\n",
    "        seq_id = lines[i].strip()[1:]  # Remove '>' from the header\n",
    "        seq = lines[i+1].strip()\n",
    "        data.append((seq_id, seq))\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Function to convert sequences to numerical format\n",
    "def seq_to_num(seqs, bp):\n",
    "    char_to_num = {\n",
    "        \"A\": 1, \"a\": 1, \"B\": 2, \"b\": 2, \"C\": 3, \"c\": 3,\n",
    "        \"D\": 4, \"d\": 4, \"E\": 5, \"e\": 5, \"F\": 6, \"f\": 6,\n",
    "        \"G\": 7, \"g\": 7, \"H\": 8, \"h\": 8, \"I\": 9, \"i\": 9,\n",
    "        \"J\": 10, \"j\": 10, \"K\": 11, \"k\": 11, \"L\": 12, \"l\": 12,\n",
    "        \"M\": 13, \"m\": 13, \"N\": 14, \"n\": 14, \"O\": 15, \"o\": 15,\n",
    "        \"P\": 16, \"p\": 16, \"Q\": 17, \"q\": 17, \"R\": 18, \"r\": 18,\n",
    "        \"S\": 19, \"s\": 19, \"T\": 20, \"t\": 20, \"U\": 21, \"u\": 21,\n",
    "        \"V\": 22, \"v\": 22, \"W\": 23, \"w\": 23, \"X\": 24, \"x\": 24,\n",
    "        \"Y\": 25, \"y\": 25, \"Z\": 26, \"z\": 26, \".\": 27, \"#\": 28,\n",
    "        \"~\": 29, \"*\": 30\n",
    "    }\n",
    "    \n",
    "    seqs_num = []\n",
    "    for seq in seqs:\n",
    "        seq_num = [char_to_num.get(char, 0) for char in seq]\n",
    "        seqs_num.append(seq_num)\n",
    "    \n",
    "    return np.array(seqs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script\n",
    "input_file = \"ttc.fasta\"\n",
    "output_file = input_file.replace(\".fasta\", \".cnn.output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess data\n",
    "data = read_fasta(input_file)\n",
    "data_labels = np.array([int(seq_id.split(\"_\")[-1]) for seq_id, _ in data])\n",
    "data_seqs = [seq for _, seq in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequences to numerical format\n",
    "bp = 240  # NRTI sequence length\n",
    "seqs_num = seq_to_num(data_seqs, bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "data_f = pad_sequences(seqs_num, padding=\"post\", maxlen=bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "validation_scores = []  # To store accuracy for each fold\n",
    "eval_list = []  # To store evaluation results for each fold\n",
    "rocout_list = []  # To store ROC outputs for each fold\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate performance metrics\n",
    "def perf_measure(y_ref, y_pred):\n",
    "    TP = np.sum((y_ref == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_ref == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_ref == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_ref == 1) & (y_pred == 0))\n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(data_f)):\n",
    "    print(f\"Processing fold {fold + 1}...\")\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    train_data, val_data = data_f[train_idx], data_f[val_idx]\n",
    "    train_labels, val_labels = data_labels[train_idx], data_labels[val_idx]\n",
    "    \n",
    "    # Calculate class weights\n",
    "    zero = np.sum(train_labels == 0)\n",
    "    one = np.sum(train_labels == 1)\n",
    "    weight_0 = 1\n",
    "    weight_1 = zero / one\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = get_model(bp, nunits=99)\n",
    "    model.fit(\n",
    "        train_data,\n",
    "        train_labels,\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        class_weight={0: weight_0, 1: weight_1},\n",
    "        verbose=1\n",
    "    )\n",
    "    # Evaluate the model on the validation set\n",
    "    results = model.evaluate(val_data, val_labels, verbose=0)\n",
    "    validation_scores.append(results[1])  # Store accuracy\n",
    "    print(f\"Results for fold {fold + 1}: {results}\")\n",
    "    \n",
    "    # Predict classes and calculate performance metrics\n",
    "    val_preds = (model.predict(val_data) > 0.5).astype(int)\n",
    "    TP, FP, TN, FN = perf_measure(val_labels, val_preds)\n",
    "    print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
    "    \n",
    "    # Save evaluation results to a dictionary\n",
    "    eval_results = {\n",
    "        \"fold\": fold + 1,\n",
    "        \"accuracy\": results[1],\n",
    "        \"loss\": results[0],\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"TN\": TN,\n",
    "        \"FN\": FN\n",
    "    }\n",
    "    eval_list.append(eval_results)\n",
    "    \n",
    "    # ROC output\n",
    "    preds_proba = model.predict(val_data)\n",
    "    rocout = np.column_stack((preds_proba, val_preds, val_labels))\n",
    "    rocout_list.append(rocout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation results to a CSV file\n",
    "eval_df = pd.DataFrame(eval_list)\n",
    "eval_df.to_csv(f\"{input_file}.eval_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ROC outputs to separate CSV files\n",
    "for fold, rocout in enumerate(rocout_list):\n",
    "    roc_df = pd.DataFrame(rocout, columns=[\"Predicted_Probability\", \"Predicted_Class\", \"True_Label\"])\n",
    "    roc_df.to_csv(f\"{input_file}.roc.fold_{fold + 1}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
